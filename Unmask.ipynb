{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326348da",
   "metadata": {},
   "source": [
    "# Mapping mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c987f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To create and filter synthetic maps\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "images = \"dataset/no_mask\"\n",
    "images_masked = \"dataset/mask\"\n",
    "counter = 0 # Counter used for masked images\n",
    "counter_elimination = 0 # Counter used for number of original images eliminated\n",
    "\n",
    "'''\n",
    "Function to create a list of directory entries\n",
    "'''\n",
    "def find_path(im):\n",
    "    try:\n",
    "        imlist = [osp.join(osp.realpath('.'), im, img) for img in os.listdir(im) if os.path.splitext(img)[1] ==\n",
    "                  '.png' or os.path.splitext(img)[1] == '.jpeg' or os.path.splitext(img)[1] == '.jpg']\n",
    "    except NotADirectoryError:\n",
    "        imlist = []\n",
    "        imlist.append(osp.join(osp.realpath('.'), im))\n",
    "    except FileNotFoundError:\n",
    "        print(\"No file or directory with the name {}\".format(im))\n",
    "        exit()\n",
    "    return imlist\n",
    "\n",
    "'''\n",
    "Function to check if for each original image \n",
    "there is its counterpart masked\n",
    "'''\n",
    "def name_check(img, img_mask):\n",
    "    path1, name1 = os.path.split(img)\n",
    "    path2, name2 = os.path.split(img_mask)\n",
    "    name1 = name1[:-4]\n",
    "    search = name2.find(name1)\n",
    "    if search > -1:\n",
    "        return True, name1\n",
    "    print(name1+\" Not found!\")\n",
    "    return False, name1\n",
    "\n",
    "'''\n",
    "Function to eliminate intermediate value \n",
    "and obtain only black and white values\n",
    "'''\n",
    "\n",
    "def binarization(n, map): # n is arbitrary chosen after several tests\n",
    "    for i in range(0, 256):\n",
    "        for j in range(0, 256):\n",
    "            if map[i, j]<n:\n",
    "                map[i, j] = 0\n",
    "            else:\n",
    "                map[i, j] = 255\n",
    "\n",
    "\n",
    "def filter(image):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel) # Filter with erosion and dilation \n",
    "\n",
    "imlist = find_path(images)\n",
    "imlist2 = find_path(images_masked)\n",
    "\n",
    "for image in imlist:\n",
    "    image_masked = imlist2[counter]\n",
    "    flag, name = name_check(image, image_masked)\n",
    "    if flag: \n",
    "        counter += 1\n",
    "        image = cv2.imread(image)\n",
    "        #cv2.imshow('originale', image)\n",
    "        image_masked = cv2.imread(image_masked)\n",
    "        #cv2.imshow('Masked', image_masked)\n",
    "        imMap = cv2.absdiff(image_masked, image) # Difference between original image and corresponding masked image\n",
    "        imMap = cv2.cvtColor(imMap, cv2.COLOR_BGR2GRAY)\n",
    "        imMap = np.array(imMap)\n",
    "        binarization(6, imMap)\n",
    "        #cv2.imshow('Map with noise', imMap)\n",
    "        openingMap = filter(imMap)\n",
    "        cv2.imwrite('dataset/maps/'+name+'.jpg', openingMap)\n",
    "        #cv2.imshow('Erosion and dilation', openingMap)\n",
    "        #cv2.waitKey(0)\n",
    "    else:\n",
    "        os.remove(image)\n",
    "        print(\"Removed\")\n",
    "        counter_elimination += 1\n",
    "\n",
    "print(\"Elaborate \"+str(counter)+\" images\")\n",
    "print(\"Eliminate \"+str(counter_elimination)+\" images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb76e7b7",
   "metadata": {},
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preparation dataset for both modules\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import *\n",
    "\n",
    "\n",
    "'''\n",
    "Training directories\n",
    "'''\n",
    "dsize = (128, 128)\n",
    "images = \"dataset/mask\"\n",
    "images_map = \"dataset/maps\"\n",
    "images_GAN_gt = \"dataset/no_mask\"\n",
    "\n",
    "'''\n",
    "Testing directories\n",
    "'''\n",
    "path_test = \"testing/test_mask\"\n",
    "path_test_map = \"testing/test_map\"\n",
    "path_test_gt = \"testing/test_nomask\"\n",
    "\n",
    "def normalize_seg(image): # Normalization between 0 and 1\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def normalize_GAN(image): # Normalization between -1 and 1\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def prepare_tf_segmentation():\n",
    "    X_train = image_dataset_from_directory(images, image_size=dsize, color_mode=\"grayscale\", label_mode=None, validation_split=0.2, subset=\"training\", shuffle=True, seed = 1, interpolation=\"lanczos5\")\n",
    "    X_val = image_dataset_from_directory(images, image_size=dsize, color_mode=\"grayscale\", label_mode=None, validation_split=0.2, subset=\"validation\", shuffle=True, seed = 1, interpolation=\"lanczos5\")\n",
    "    Y_train = image_dataset_from_directory(images_map, image_size=dsize, color_mode=\"grayscale\", label_mode=None, validation_split=0.2, subset=\"training\",shuffle=True, seed = 1, interpolation=\"lanczos5\")\n",
    "    Y_val = image_dataset_from_directory(images_map, image_size=dsize, color_mode=\"grayscale\", label_mode=None, validation_split=0.2, subset=\"validation\", shuffle=True, seed = 1, interpolation=\"lanczos5\")\n",
    "    X_train = X_train.map(normalize_seg)\n",
    "    Y_train = Y_train.map(normalize_seg)\n",
    "    dataset = tf.data.Dataset.zip((X_train , Y_train))\n",
    "    X_val = X_val.map(normalize_seg)\n",
    "    Y_val = Y_val.map(normalize_seg)\n",
    "    dataval = tf.data.Dataset.zip((X_val , Y_val))\n",
    "    return dataset, dataval\n",
    "\n",
    "def prepare_tf_GAN():\n",
    "    mask_ds = image_dataset_from_directory(images, image_size=dsize, label_mode=None, validation_split=0.05, subset=\"training\", shuffle=True, seed = 1, interpolation=\"lanczos5\", batch_size=16)\n",
    "    mask_ds_test = image_dataset_from_directory(images, image_size=dsize, label_mode=None, validation_split=0.05, subset=\"validation\", shuffle=True, seed = 47, interpolation=\"lanczos5\", batch_size=16)\n",
    "    map_ds = image_dataset_from_directory(images_map, image_size=dsize, color_mode=\"grayscale\", label_mode=None, validation_split=0.05, subset=\"training\",shuffle=True, seed = 1, interpolation=\"lanczos5\", batch_size=16)\n",
    "    map_ds_test = image_dataset_from_directory(images_map, image_size=dsize, color_mode=\"grayscale\", label_mode=None, validation_split=0.05, subset=\"validation\", shuffle=True, seed = 47, interpolation=\"lanczos5\", batch_size=16)\n",
    "    gt_ds = image_dataset_from_directory(images_GAN_gt, image_size=dsize, label_mode=None, validation_split=0.05, subset=\"training\",shuffle=True, seed = 1, interpolation=\"lanczos5\", batch_size=16)\n",
    "    gt_ds_test = image_dataset_from_directory(images_GAN_gt, image_size=dsize, label_mode=None, validation_split=0.05, subset=\"validation\", shuffle=True, seed = 47, interpolation=\"lanczos5\", batch_size=16)\n",
    "    mask_ds = mask_ds.map(normalize_GAN)\n",
    "    map_ds = map_ds.map(normalize_GAN)\n",
    "    mask_ds_test = mask_ds_test.map(normalize_GAN)\n",
    "    map_ds_test = map_ds_test.map(normalize_GAN)\n",
    "    gt_ds = gt_ds.map(normalize_GAN)\n",
    "    gt_ds_test = gt_ds_test.map(normalize_GAN)\n",
    "    dataset = tf.data.Dataset.zip((mask_ds, map_ds, gt_ds))\n",
    "    testset = tf.data.Dataset.zip((mask_ds_test, map_ds_test, gt_ds_test))\n",
    "    return dataset, testset\n",
    "\t\n",
    "def prepare_tf_testseg():\n",
    "\tmask_seg = image_dataset_from_directory(path_test, image_size=dsize, color_mode='grayscale', label_mode=None, shuffle=False, interpolation=\"lanczos5\", batch_size=16)\n",
    "\tmask_seg = mask_seg.map(normalize_seg)\n",
    "\timlist = find_path(path_test+\"/test_masked\")\n",
    "\tnames=[]\n",
    "\tfor i in imlist:\n",
    "\t\ti = i.split(\"/\")\n",
    "\t\tname = i[-1]\n",
    "\t\tname = name.split('_')\n",
    "\t\tname = name[0]\n",
    "\t\tnames.append(name)\n",
    "\treturn names, mask_seg\n",
    "\t\n",
    "def prepare_tf_testset():\n",
    "\tmap = image_dataset_from_directory(path_test_map, image_size=dsize, color_mode='grayscale', label_mode=None, shuffle=False, interpolation=\"lanczos5\", batch_size=16)\n",
    "\tmask_GAN = image_dataset_from_directory(path_test, image_size=dsize, label_mode=None, shuffle=False, interpolation=\"lanczos5\", batch_size=16)\n",
    "\t# gt_GAN = image_dataset_from_directory(path_test_gt, image_size=dsize, label_mode=None, shuffle=False, interpolation=\"lanczos5\", batch_size=16)\n",
    "\tmap = map.map(normalize_GAN)\n",
    "\tmask_GAN = mask_GAN.map(normalize_GAN)\n",
    "\t# gt_GAN = gt_GAN.map(normalize_GAN)\n",
    "\ttestset = tf.data.Dataset.zip((mask_GAN,map))\n",
    "\treturn testset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb4dbb",
   "metadata": {},
   "source": [
    "# Editing module model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition Editing Module\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "'''\n",
    "Preparing inputs for mask region discriminator\n",
    "Methodology for selecting mask region from original image\n",
    "'''\n",
    "def prepare_input_disc_mask(x):\n",
    "    Igt_Iedit = x[0]\n",
    "    Imask_map = x[1]\n",
    "    Iinput = x[2]\n",
    "    Imask_map = Imask_map/255.0\n",
    "    complementary = 1-Imask_map\n",
    "    firstmul = Multiply()([Iinput, complementary])\n",
    "    secondmul = Multiply()([Igt_Iedit, Imask_map])\n",
    "    Imask_region = Add()([firstmul, secondmul])\n",
    "    return Imask_region\n",
    "\n",
    "'''\n",
    "Squeeze and Excitation block\n",
    "'''\n",
    "def se_block(in_block, ch, ratio=16):\n",
    "    x = GlobalAveragePooling2D()(in_block)\n",
    "    x = Dense(ch//ratio, activation='relu')(x)\n",
    "    x = Dense(ch, activation='sigmoid')(x)\n",
    "    return Multiply()([in_block, x])\n",
    "\n",
    "'''\n",
    "Generator\n",
    "'''\n",
    "def generator():\n",
    "    input_size = (128, 128, 3)\n",
    "    \n",
    "    input_mask = Input(input_size)\n",
    "    input_map = Input((128, 128, 1))\n",
    "    inputs = concatenate([input_mask, input_map])\n",
    "\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, padding='same')(pool1)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(128, 3, padding='same')(conv2)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    # se = se_block(pool1, ch=1)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, padding='same', dilation_rate=(2, 2))(pool2)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, 3, padding='same', dilation_rate=(4, 4))(conv3)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, 3, padding='same', dilation_rate=(8, 8))(conv3)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, 3, padding='same', dilation_rate=(16, 16))(conv3)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    up4 = Conv2DTranspose(128, 3, strides=(2, 2), padding='same')(conv3)\n",
    "    merge4 = concatenate([conv2, up4])\n",
    "    conv4 = Conv2D(128, 3, padding='same')(merge4)\n",
    "    conv4 = LeakyReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(128, 3, padding='same')(conv4)\n",
    "    conv4 = LeakyReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    up5 = Conv2DTranspose(64, 3, strides=(2, 2), padding='same')(conv4)\n",
    "    merge5 = concatenate([conv1, up5])\n",
    "    conv5 = Conv2D(64, 3, padding='same')(merge5)\n",
    "    conv5 = LeakyReLU()(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(64, 3, padding='same')(conv5)\n",
    "    conv5 = LeakyReLU()(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(3, 3, padding='same')(conv5)\n",
    "    conv5 = LeakyReLU()(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(3, 1, activation='tanh')(conv5)\n",
    "\n",
    "    generator = Model(inputs=[input_mask, input_map], outputs=conv5)\n",
    "    #generator.summary()\n",
    "    #plot_model(model, show_shapes=True, to_file='unet_model.png')\n",
    "\n",
    "    return generator\n",
    "\n",
    "'''\n",
    "Whole region discriminator\n",
    "'''\n",
    "def disc_whole_region():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    input_size = (128, 128, 3)\n",
    "\n",
    "    input = Input(input_size)\n",
    "    conv1 = Conv2D(64, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(input)\n",
    "    conv1 = LeakyReLU()(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "\n",
    "    zero_pad4 = ZeroPadding2D()(conv3)  \n",
    "    conv4 = Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad4)  \n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = LeakyReLU()(conv4)\n",
    "\n",
    "    zero_pad5 = ZeroPadding2D()(conv4)  \n",
    "    conv5 = Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad5)  \n",
    "    discriminator = Model(inputs=input, outputs=conv5)\n",
    "    return discriminator\n",
    "\n",
    "'''\n",
    "Mask region discriminator\n",
    "'''\n",
    "def disc_mask_region():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    input_size = (128, 128, 3)\n",
    "\n",
    "    Igt_Iedit = Input(input_size) # Ground truth or generated image\n",
    "    Imask_map = Input((128, 128, 1)) # Mask map image\n",
    "    Iinput = Input(input_size) # Original image\n",
    "    input = Lambda(prepare_input_disc_mask)([Igt_Iedit, Imask_map, Iinput]) # preparation inputs\n",
    "\n",
    "    conv1 = Conv2D(64, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(input)\n",
    "    conv1 = LeakyReLU()(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "\n",
    "    zero_pad4 = ZeroPadding2D()(conv3)  \n",
    "    conv4 = Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad4)  \n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = LeakyReLU()(conv4)\n",
    "\n",
    "    zero_pad5 = ZeroPadding2D()(conv4)  \n",
    "    conv5 = Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad5)  \n",
    "\n",
    "    discriminator = Model(inputs=[Igt_Iedit, Imask_map, Iinput], outputs=conv5)\n",
    "\n",
    "    #discriminator.summary()\n",
    "    #plot_model(discriminator, show_shapes=True)\n",
    "    return discriminator\n",
    "\n",
    "'''\n",
    "Perceptual network\n",
    "'''\n",
    "def vgg19_model():\n",
    "    selected_layers = [\"block3_conv4\", \"block4_conv4\", \"block5_conv4\"]\n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape=(128, 128, 3))\n",
    "    vgg.trainable = False\n",
    "    outputs = [vgg.get_layer(l).output for l in selected_layers]\n",
    "    vgg_model = Model(vgg.input, outputs)\n",
    "    #vgg_model.summary()\n",
    "    return vgg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b99d4",
   "metadata": {},
   "source": [
    "# Map module model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32941de",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition Map Module\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "def seg_model():\n",
    "    input_size = (128, 128, 1)\n",
    "\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, padding='same')(pool1)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(128, 3, padding='same')(conv2)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, padding='same')(pool2)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, 3, padding='same')(conv3)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, padding='same')(pool3)\n",
    "    conv4 = LeakyReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(512, 3, padding='same')(conv4)\n",
    "    conv4 = LeakyReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, padding='same')(pool4)\n",
    "    conv5 = LeakyReLU()(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(1024, 3, padding='same')(conv5)\n",
    "    conv5 = LeakyReLU()(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "    up6 = Conv2DTranspose(512, 3, strides=(2, 2), padding='same')(conv5)\n",
    "    merge6 = concatenate([conv4, up6])\n",
    "    conv6 = Conv2D(512, 3, padding='same')(merge6)\n",
    "    conv6 = LeakyReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(512, 3, padding='same')(conv6)\n",
    "    conv6 = LeakyReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(256, 3, strides=(2, 2), padding='same')(conv6)\n",
    "    merge7 = concatenate([conv3, up7])\n",
    "    conv7 = Conv2D(256, 3, padding='same')(merge7)\n",
    "    conv7 = LeakyReLU()(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(256, 3, padding='same')(conv7)\n",
    "    conv7 = LeakyReLU()(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(128, 3, strides=(2, 2), padding='same')(conv7)\n",
    "    merge8 = concatenate([conv2, up8])\n",
    "    conv8 = Conv2D(128, 3, padding='same')(merge8)\n",
    "    conv8 = LeakyReLU()(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(128, 3, padding='same')(conv8)\n",
    "    conv8 = LeakyReLU()(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(64, 3, strides=(2, 2), padding='same')(conv8)\n",
    "    merge9 = concatenate([conv1, up9])\n",
    "    conv9 = Conv2D(64, 3, activation='tanh', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='tanh', padding='same')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='tanh', padding='same')(conv9)\n",
    "    conv9 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv9)\n",
    "\n",
    "    model.summary()\n",
    "    #plot_model(model, show_shapes=True, to_file='unet_model.png')\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165cb11c",
   "metadata": {},
   "source": [
    "# Train editing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606045ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training Editing Module\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from PIL import Image\n",
    "\n",
    "'''\n",
    "Code to avoid OoM\n",
    "'''\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "'''\n",
    "Variables and optimizers initialization \n",
    "Loading models and dataset \n",
    "'''\n",
    "count=1\n",
    "EPOCHS=100\n",
    "\n",
    "log_dir=\"logs/\"\n",
    "summary_writer = tf.summary.create_file_writer(log_dir + \"fit/final_loss\")\n",
    "\n",
    "gen = generator()\n",
    "disc_whole = disc_whole_region()\n",
    "disc_mask = disc_mask_region()\n",
    "vgg_model = vgg19_model()\n",
    "print(\"Model Created\")\n",
    "\n",
    "train_ds, test_ds = prepare_tf_GAN()\n",
    "print(\"Data uploaded\")\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "LAMBDA_whole = 0.3\n",
    "LAMBDA_mask = 0.7\n",
    "LAMBDA_rc = 100\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "disc_whole_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "disc_mask_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "'''\n",
    "Definition of perceptual loss\n",
    "'''\n",
    "@tf.function\n",
    "def perceptual_loss(gen_image, gt_image):\n",
    "    h1_list = vgg_model(gen_image)\n",
    "    h2_list = vgg_model(gt_image)\n",
    "    perc_loss = 0.0\n",
    "    for h1, h2 in zip(h1_list, h2_list):\n",
    "        h1 = K.batch_flatten(h1)\n",
    "        h2 = K.batch_flatten(h2)\n",
    "        perc_loss += K.sum(K.square(h1 - h2), axis=-1)\n",
    "    perc_loss = tf.reduce_mean(perc_loss)\n",
    "    return perc_loss\n",
    "\n",
    "'''\n",
    "Definition of Non-Saturating loss for discriminator and generator\n",
    "'''\n",
    "def disc_loss(disc_real_output, disc_gen_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(disc_real_output), disc_real_output) # Real samples\n",
    "    fake_loss = cross_entropy(tf.zeros_like(disc_gen_output), disc_gen_output) # Fake samples\n",
    "    total_loss = (real_loss + fake_loss)\n",
    "    return total_loss\n",
    "\n",
    "def gen_loss(disc_gen_output):\n",
    "    adv_loss = cross_entropy(tf.ones_like(disc_gen_output), disc_gen_output) # Adversarial loss\n",
    "    return adv_loss\n",
    "\n",
    "'''\n",
    "Definition of recostrunction loss\n",
    "'''\n",
    "def rec_loss(gen_output, Igt):\n",
    "    l1_loss = tf.reduce_mean(tf.abs(Igt - gen_output)) # L1 loss\n",
    "    SSIM_loss = 1 - tf.reduce_mean(tf.image.ssim(gen_output, Igt, max_val=2.0)) # SSIM loss\n",
    "    rc_loss = l1_loss + SSIM_loss\n",
    "    return rc_loss\n",
    "\n",
    "'''\n",
    "First part of training\n",
    "Training of generator, whole region discriminator and perceptual network\n",
    "'''\n",
    "@tf.function\n",
    "def first_train_cycle(input_image, input_map, Igt, epoch, n):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_image = gen([input_image, input_map], training=True)\n",
    "\n",
    "        real_output = disc_whole(input_image, training=True)\n",
    "        fake_output = disc_whole(generated_image, training=True)\n",
    "\n",
    "        generator_loss = gen_loss(fake_output)\n",
    "        discriminator_loss = disc_loss(real_output, fake_output)\n",
    "        rc_loss = rec_loss(generated_image, Igt)\n",
    "        perc_loss = perceptual_loss(generated_image, Igt)\n",
    "        gen_tot_loss = LAMBDA_rc*(rc_loss + perc_loss) + generator_loss\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_tot_loss, gen.trainable_variables)\n",
    "    gradients_of_disc_whole = disc_tape.gradient(discriminator_loss, disc_whole.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n",
    "    disc_whole_optimizer.apply_gradients(zip(gradients_of_disc_whole, disc_whole.trainable_variables))\n",
    "\n",
    "    with summary_writer.as_default(): # Plotting of losses with Tensorboard\n",
    "        tf.summary.scalar('gan_loss', gen_tot_loss, step=epoch)\n",
    "        tf.summary.scalar('generator_loss', generator_loss, step=epoch)\n",
    "        tf.summary.scalar('reconstruction_loss', rc_loss, step=epoch)\n",
    "        tf.summary.scalar('perceptual_loss', perc_loss, step=epoch)\n",
    "        tf.summary.scalar('disc_whole_loss', discriminator_loss, step=epoch)\n",
    "\n",
    "'''\n",
    "Second part of training\n",
    "Training of generator, whole region discriminator, mask region discriminator and perceptual network\n",
    "'''\n",
    "@tf.function\n",
    "def second_train_cycle(input_image, input_map, Igt, epoch, n):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_whole_tape, tf.GradientTape() as disc_mask_tape:\n",
    "        generated_image = gen([input_image, input_map], training=True)\n",
    "\n",
    "        real_output_whole = disc_whole(input_image, training=True)\n",
    "        fake_output_whole = disc_whole(generated_image, training=True)\n",
    "        real_output_mask = disc_mask([Igt, input_map, input_image], training=True)\n",
    "        fake_output_mask = disc_mask([generated_image, input_map, input_image], training=True)\n",
    "\n",
    "        gen_loss_whole = gen_loss(fake_output_whole)\n",
    "        disc_loss_whole = LAMBDA_whole * disc_loss(real_output_whole, fake_output_whole)\n",
    "        gen_loss_mask = gen_loss(fake_output_mask)\n",
    "        disc_loss_mask = LAMBDA_mask * disc_loss(real_output_mask, fake_output_mask)\n",
    "        rc_loss = rec_loss(generated_image, Igt)\n",
    "        perc_loss = perceptual_loss(generated_image, Igt)\n",
    "        gen_tot_loss = LAMBDA_rc*(rc_loss + perc_loss) + LAMBDA_whole*(gen_loss_whole) + LAMBDA_mask*(gen_loss_mask)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_tot_loss, gen.trainable_variables)\n",
    "    gradients_of_disc_whole = disc_whole_tape.gradient(disc_loss_whole, disc_whole.trainable_variables)\n",
    "    gradients_of_disc_mask = disc_mask_tape.gradient(disc_loss_mask, disc_mask.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n",
    "    disc_whole_optimizer.apply_gradients(zip(gradients_of_disc_whole, disc_whole.trainable_variables))\n",
    "    disc_mask_optimizer.apply_gradients(zip(gradients_of_disc_mask, disc_mask.trainable_variables))\n",
    "\n",
    "    with summary_writer.as_default(): # Plotting of losses with Tensorboard\n",
    "        tf.summary.scalar('gan_loss', gen_tot_loss, step=epoch)\n",
    "        tf.summary.scalar('generator_loss', (gen_loss_mask+gen_loss_whole), step=epoch)\n",
    "        tf.summary.scalar('reconstruction_loss', rc_loss, step=epoch)\n",
    "        tf.summary.scalar('perceptual_loss', perc_loss, step=epoch)\n",
    "        tf.summary.scalar('disc_whole_loss', disc_loss_whole, step=epoch)\n",
    "        tf.summary.scalar('disc_mask_loss', disc_loss_mask, step=epoch)\n",
    "\n",
    "'''\n",
    "Generation of fake samples starting from testset\n",
    "Computation of average SSIM and PSNR for each epoch\n",
    "'''\n",
    "def generate_images(model, test_input, test_map, tar, epoch):\n",
    "    prediction = model([test_input, test_map], training=True)\n",
    "    score_SSIM = tf.image.ssim(prediction, tar, max_val=2.0)\n",
    "    score_PSNR = tf.image.psnr(prediction, tar, max_val=2.0)\n",
    "    np_score_PSNR=score_PSNR.numpy()\n",
    "    average_PSNR = np.average(np_score_PSNR)\n",
    "    np_score_SSIM=score_SSIM.numpy()\n",
    "    average_SSIM = np.average(np_score_SSIM)\n",
    "    with summary_writer.as_default(): # Plotting of metrics with Tensorboard\n",
    "        tf.summary.scalar('SSIM', average_SSIM, step=epoch)\n",
    "        tf.summary.scalar('PSNR', average_PSNR, step=epoch)\n",
    "    # Saving of first image of the batch (for each epoch) with corresponding SSIM and PSNR\n",
    "    fig=plt.figure(figsize=(15, 7.5))\n",
    "    fig.text(0.5, 0.15, \"SSIM: \" + str(np_score_SSIM[0]), fontsize=20, horizontalalignment=\"center\")\n",
    "    fig.text(0.5, 0.1, \"PSNR: \" + str(np_score_PSNR[0]) + \"dB\", fontsize=20, horizontalalignment=\"center\")\n",
    "    plt.suptitle(\"Epoch \" + str(epoch+1), fontsize=20, ha=\"center\")\n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = ['Test Input', 'Ground Truth', 'Predicted Image']\n",
    "    global count\n",
    "    stringa =\"result/GAN/final_loss/\" + str(count) + \".png\"\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i], fontsize=16)\n",
    "        # Getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    # plt.show()\n",
    "    fig.savefig(stringa)\n",
    "    \n",
    "    # Saving of the image with the best SSIM and PSNR (for each epoch)\n",
    "    index_SSIM = tf.argmax(score_SSIM)\n",
    "    index_PSNR = tf.argmax(score_PSNR)\n",
    "    fig=plt.figure(figsize=(30, 15))\n",
    "    fig.text(0.5, 0.07, \"SSIM: \" + str(np_score_SSIM[index_SSIM]), fontsize=28, horizontalalignment=\"center\")\n",
    "    fig.text(0.5, 0.03, \"PSNR: \" + str(np_score_PSNR[index_PSNR]) + \"dB\", fontsize=28, horizontalalignment=\"center\")\n",
    "    plt.suptitle(\"Epoch \" + str(epoch+1), fontsize=40, ha=\"center\")\n",
    "    display_list = [test_input[index_SSIM], tar[index_SSIM], prediction[index_SSIM], test_input[index_PSNR], tar[index_PSNR], prediction[index_PSNR]]\n",
    "    title = ['SSIM_Test Input', 'SSIM_Ground Truth', 'SSIM_Predicted Image','PSNR_Test Input', 'PSNR_Ground Truth', 'PSNR_Predicted Image']\n",
    "    stringa =\"result/GAN/SSIM_PSNR/\" + str(count) + \".png\"\n",
    "    count += 1\n",
    "    for i in range(6):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.title(title[i], fontsize=22)\n",
    "        # Getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    # plt.show()\n",
    "    fig.savefig(stringa)\n",
    "\n",
    "'''\n",
    "Training\n",
    "'''\n",
    "def fit(train_ds, epochs, test_ds):\n",
    "    first_epochs = int(round(epochs * 0.4)) # Variable to differentiate training\n",
    "    for epoch in range(0, epochs):\n",
    "        if epoch < first_epochs:\n",
    "            print(\"First training cycle\")\n",
    "        else:\n",
    "            print(\"Second training cycle\")\n",
    "        counter = 0\n",
    "        start = time.time()\n",
    "        print(\"Epoch: \", str(epoch+1))   \n",
    "\n",
    "        for n, (input_image, input_map, target) in train_ds.enumerate():\n",
    "            counter+=1\n",
    "            print(str(counter), end=' ', flush=True)\n",
    "            if epoch < first_epochs:\n",
    "                first_train_cycle(input_image, input_map, target, epoch, n)\n",
    "            else:\n",
    "                second_train_cycle(input_image, input_map, target, epoch, n)\n",
    "        for example_input, example_map, example_target in test_ds.take(1):\n",
    "            generate_images(gen, example_input, example_map, example_target, epoch)\n",
    "        # Saving (checkpoint) the model every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            print(\"Checkpoint saved!\")\n",
    "\n",
    "        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "'''\n",
    "Checkpoint management\n",
    "'''\n",
    "checkpoint_dir = './Checkpoints/GAN/final_loss'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer, disc_whole_optimizer=disc_whole_optimizer, disc_mask_optimizer=disc_mask_optimizer, generator=gen, disc_whole=disc_whole, disc_mask=disc_mask)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)\n",
    "checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "'''\n",
    "Start training\n",
    "'''\n",
    "fit(train_ds, EPOCHS, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf7389",
   "metadata": {},
   "source": [
    "# Train mapping module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training Map Module\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "Code to avoid OoM\n",
    "'''\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "'''\n",
    "Loading dataset and training\n",
    "'''\n",
    "model = seg_model()\n",
    "dataset, dataval = prepare_tf_segmentation()\n",
    "print(\"Uploaded the data\")\n",
    "\n",
    "history = model.fit(dataset, validation_data=dataval, epochs=20)\n",
    "model.save('segmentation_model_20k_20epoch.h5')\n",
    "\n",
    "'''\n",
    "Plotting Loss and Accuracy\n",
    "'''\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f01d4b",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772db847",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Testing whole architecture\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import *\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Code to avoid OoM\n",
    "'''\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "'''\n",
    "Function to eliminate intermediate values\n",
    "and obtain only black and white values\n",
    "'''\n",
    "def binarization(n, map):\n",
    "    for i in range(0, 128):\n",
    "        for j in range(0, 128):\n",
    "            if map[i, j]<n:\n",
    "                map[i, j] = 0\n",
    "            else:\n",
    "                map[i, j] = 1\n",
    "\n",
    "'''\n",
    "Segmentation\n",
    "'''\n",
    "def map_generation(images, names):\n",
    "    prediction = seg_model.predict(x = images)\n",
    "    count = 0\n",
    "    stringa = \"testing/test_map/test/\"\n",
    "    for image in prediction:\n",
    "        binarization(0.01, image)\n",
    "        image = filter(image)\n",
    "        image = image.reshape(128,128,1)\n",
    "        tf.keras.preprocessing.image.save_img(stringa+names[count]+'.jpg', image)\n",
    "        count+=1  \n",
    "\n",
    "'''\n",
    "Generation synthetic unmasked images\n",
    "'''\n",
    "def generate_image(model, test_input, test_map, names):\n",
    "    global count\n",
    "    prediction = model([test_input, test_map], training=True)\n",
    "    fig=plt.figure(figsize=(15, 7.5))\n",
    "    plt.suptitle(\"TEST\", fontsize=24, ha=\"center\")\n",
    "    display_list = [test_input[0, :, :, :], test_map[0, :, :, :], prediction[0, :, :, :]]\n",
    "    title = ['Test Input', 'Segmentation Map', 'Predicted Image']\n",
    "    stringa =\"testing/results/\"\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i], fontsize=18)\n",
    "        # Getting the pixel values between [0, 1] to plot it.\n",
    "        if i == 1:\n",
    "            plt.imshow(display_list[i], cmap = 'gray')\n",
    "        else:\n",
    "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    tf.keras.preprocessing.image.save_img(stringa+names[count]+'.jpg', prediction[0, :, :, :])\n",
    "    # fig.savefig(stringa+names[count]+'.jpg')\n",
    "    plt.close('all')\n",
    "    count+=1\n",
    "\n",
    "def compute_metrics(model, test_input, test_map, tar):\n",
    "    prediction = model([test_input, test_map], training=True)\n",
    "    score_SSIM = tf.image.ssim(prediction, tar, max_val=2.0)\n",
    "    score_PSNR = tf.image.psnr(prediction, tar, max_val=2.0)\n",
    "    np_score_PSNR=score_PSNR.numpy()\n",
    "    average_PSNR = np.average(np_score_PSNR)\n",
    "    np_score_SSIM=score_SSIM.numpy()\n",
    "    average_SSIM = np.average(np_score_SSIM)\n",
    "    return average_PSNR, average_SSIM\n",
    "\n",
    "'''\n",
    "Checkpoint and models restore\n",
    "'''\n",
    "seg_model = load_model(\"Checkpoints/Segmentation/segmentation_model_20k_20epoch.h5\")\n",
    "gen = generator()\n",
    "checkpoint_dir = \"Checkpoints/GAN/final_loss\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator=gen)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)\n",
    "checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "count = 0\n",
    "names, mask_seg = prepare_tf_testseg()\n",
    "map_generation(mask_seg, names)\n",
    "print(\"Segmentation of masks: DONE\")\n",
    "testset = prepare_tf_testset()\n",
    "for n, (example_input, example_map) in testset.enumerate():\n",
    "    generate_image(gen, example_input, example_map, names)\n",
    "print(\"Generation of synthetical images: DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9b23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
